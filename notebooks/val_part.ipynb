{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GTSRB Dataset\n\n**Problem:** Implement a neural network model capable of identifying a german road sign as accuratelly as possible.\n\nIn this notebook we will start with a simple model and train it without any data augmentation. This allows us to get a base value for our accuracy, so that we can better grasp the improvements or regressions obtained from our methods.","metadata":{}},{"cell_type":"code","source":"%pip install tensorflow\n%pip install opencv-python\n%pip install tensorflow-addons\n%pip install tensorflow-datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imports\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import (\n    Conv2D, \n    Conv2DTranspose, \n    BatchNormalization, \n    LeakyReLU, \n    Flatten, \n    Dense, \n    Reshape, \n    Input,\n    Activation\n)\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,TensorBoard, ReduceLROnPlateau\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.data import AUTOTUNE\nimport tensorflow_addons as tfa\nimport tensorflow_datasets as tfds\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport cv2\n\n\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport seaborn as sn\nfrom PIL import Image\nimport glob\n\nimport os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Constants","metadata":{}},{"cell_type":"code","source":"HEIGHT = 39\nWIDTH = 39\nNUM_CHANNELS = 3 # Pictures are in RGB\nBATCH_SIZE = 32\nDATASET_PATH = '/kaggle/input/sinais/dataset'\nNUM_CLASSES = 43\nCLASS_NAMES = os.listdir(f'{DATASET_PATH}/test_images')\nEPOCHS = 128\n\nTRAIN_ONLINE = True\nTRAIN_ONLINE_AUG = True\nCONVERT_DATASET = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Auxiliary functions\nThese help with visualizing data and predictions","metadata":{}},{"cell_type":"code","source":"def plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(CLASS_NAMES[predicted_label],\n                                100*np.max(predictions_array),\n                                CLASS_NAMES[true_label]),\n                                color=color)\n\ndef show_batch(image_batch, label_batch):\n  columns = 8\n  rows = BATCH_SIZE / columns + 1  \n  plt.figure(figsize=(10, 2 * rows))\n  for n in range(BATCH_SIZE):\n      ax = plt.subplot(int(rows), columns, n+1)\n      plt.imshow((image_batch[n]))\n      plt.title(classNames[label_batch[n]==1][0])\n      plt.axis('off')\n\ndef plot_value_array(i, predictions_array, true_label):\n  predictions_array, true_label = predictions_array, true_label[i]\n  plt.grid(False)\n  plt.xticks(range(10))\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1])\n  predicted_label = np.argmax(predictions_array)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')\n\n# Plot the first X test images, their predicted labels, and the true labels.\n# Color correct predictions in blue and incorrect predictions in red.\ndef plot_predictions(predictions, ground_truth, num_rows= 5, num_cols=3 ):\n\n    num_images = num_rows*num_cols\n    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n    for i in range(num_images):\n        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n        plot_image(i, predictions[i], ground_truth, x_test)\n        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n        plot_value_array(i, predictions[i], ground_truth)\n    plt.tight_layout()\n    plt.show()\n\ndef show_history(history):\n    print(history.history.keys())\n\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='lower right')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper right')\n    plt.show()    \n\n    \ndef show_confusion_matrix(model, dataset):\n\n    all_labels = []\n    all_preds = []\n\n    for images , labels in dataset.take(-1):\n        numpy_labels = labels.numpy()\n        numpy_images = images.numpy()\n        preds = model.predict(numpy_images, verbose=0)\n\n        all_labels += [np.argmax(x) for x in numpy_labels]\n        all_preds += [np.argmax(x) for x in preds]\n\n    conf_mat = tf.math.confusion_matrix(all_labels, all_preds)\n\n    df_cm = pd.DataFrame(conf_mat.numpy(), range(NUM_CLASSES), range(NUM_CLASSES))\n    plt.figure(figsize=(15,10))\n    sn.set(font_scale=1.4) # for label size\n    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d') # font size\n\n    plt.show()\n\n    res_correct = {0:0, 1:0, 2:0, 3:0,4:0,5:0,6:0,7:0}\n    res_incorrect = {0:0, 1:0, 2:0, 3:0,4:0,5:0,6:0,7:0}\n    for i in range(len(all_preds)):\n        if all_preds[i] == all_labels[i]:\n            res_correct[all_labels[i]] += 1\n        else:\n            res_incorrect[all_labels[i]] += 1\n\n    for i in range(len(res_correct)):\n\n        print('class: ', i, ' total images: ', res_correct[i] + res_incorrect[i],' % correct: ', res_correct[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_callbacks(file_path):\n\n    checkpointer = ModelCheckpoint(filepath= file_path, \n                               monitor = 'val_accuracy',\n                               verbose=1, \n                               save_weights_only=True,\n                               save_best_only=True)\n\n\n    earlyStopper = EarlyStopping(monitor='val_loss', min_delta = 0.001, patience = 25, verbose = 1)\n\n    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=0.000000001, verbose = 1)\n\n    return [checkpointer, earlyStopper, reduceLR]\n    \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert dataset to PNG\n\nFor some reason tensorflow does not support PPM","metadata":{}},{"cell_type":"code","source":"if CONVERT_DATASET:\n    for path in glob.iglob(f'{DATASET_PATH}/**/*.ppm', recursive=True):\n        img = Image.open(path, mode='r')\n        new_path = path.replace('.ppm', '.png')\n        img.save(new_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load and prepare datasets","metadata":{}},{"cell_type":"code","source":"classNames = np.array(os.listdir(f'{DATASET_PATH}/train_images/GTSRB/Final_Training/Images',))\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ndataset = tf.keras.utils.image_dataset_from_directory(\n    directory=f'{DATASET_PATH}/train_images/GTSRB/Final_Training/Images',\n    image_size=(WIDTH,HEIGHT),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    label_mode='categorical'\n)\n\ntestset = tf.keras.utils.image_dataset_from_directory(\n    directory=f'{DATASET_PATH}/test_images',\n    image_size=(WIDTH,HEIGHT),\n    batch_size=BATCH_SIZE,\n    label_mode='categorical'\n)\n\ndataset_length = dataset.cardinality().numpy()\n\nfor image, label in dataset.take(1):\n    print(\"Image shape : \",image.numpy().shape)\n    print(\"Label : \", label.numpy())\n\nprint(dataset_length)\n\n# Normalize image pixels\nnormalize = tf.keras.layers.Rescaling(1.0/255.0)\n\ndataset = dataset.map(lambda x,y: (normalize(x),y))\ntest_ds = testset.map(lambda x,y: (normalize(x),y))\n\ndataset = dataset.cache()\ndataset = dataset.shuffle(buffer_size = dataset_length)\n#dataset = dataset.batch(batch_size = BATCH_SIZE)\ndataset = dataset.prefetch(buffer_size = 10000)\n\ntest_ds = test_ds.cache()\n#test_ds = test_ds.shuffle(buffer_size = dataset_length)\n#test_ds = test_ds.batch(batch_size = BATCH_SIZE)\ntest_ds = test_ds.prefetch(buffer_size = 10000)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation Dataset","metadata":{}},{"cell_type":"code","source":"def split_val(dataset, dataset_length):\n    train_size = int(0.8 * dataset_length / BATCH_SIZE)\n    val_size = int(0.2 * dataset_length / BATCH_SIZE)\n\n    train_ds = dataset.take(train_size)\n    val_ds = dataset.skip(train_size)\n    return train_ds, val_ds\n\ntrain_ds, val_ds = split_val(dataset, dataset_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show info","metadata":{}},{"cell_type":"code","source":"image_batch, label_batch = next(iter(train_ds))        \nshow_batch(image_batch, label_batch.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get dataset info","metadata":{}},{"cell_type":"code","source":"image_batch, label_batch = next(iter(train_ds))\nnum_batches = train_ds.cardinality().numpy()\n\nprint(f'Image shape: {image_batch[0].numpy().shape}')\nprint(f'Label: {label_batch[0].numpy()}')\nprint(f'Number of batches: {num_batches}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model creation","metadata":{}},{"cell_type":"code","source":"def model_BP(width, height, num_channels):\n    model = Sequential()\n\n    model.add(Input(shape=(width,height,num_channels)))\n\n    model.add(Conv2D(64, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.02))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(64, (3,3), padding='same'))\n    model.add(LeakyReLU(alpha=0.02))\n    model.add(BatchNormalization())\n\n    model.add(Flatten())\n    model.add(Dense(64))\n    model.add(Dense(NUM_CLASSES, activation='softmax'))\n\n    opt = Adam(learning_rate=1e-3)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    print(model.summary())\n    tf.keras.utils.plot_model(model, show_shapes=True)\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"if TRAIN_ONLINE:\n    log_path = f\"logs/\"\n    model = model_BP(WIDTH, HEIGHT, NUM_CHANNELS)\n    callback = prepare_callbacks(log_path)\n    hist = model.fit(train_ds, verbose=2, \n                     batch_size=BATCH_SIZE, epochs=EPOCHS, \n                     callbacks=callback, \n                     validation_data = val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"results = model.evaluate(test_ds, verbose=2)\n\nprint(results)\n\nshow_history(hist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denoise_image(image, label):\n    if len(image.shape) == 3:\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        \n    denoised_image = cv2.fastNlMeansDenoising(image, None, h=10, templateWindowSize=7, searchWindowSize=21)\n    \n    if len(denoised_image.shape) == 2:\n        denoised_image = np.expand_dims(denoised_image, axis=-1)\n        \n    return denoised_image, label\n\ndef augment_data(images, labels):\n    augments_images = []\n    augments_labels = []\n    \n    for image, label in zip(images, labels):\n        if len(image.shape) == 3: \n            denoised_image = denoise_image(image)\n            augments_images.append(denoised_image)\n            augments_labels.append(label)\n        \n        augments_images.append(image)\n        augments_labels.append(label)\n                \n    return np.array(augments_images), np.array(augments_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\ns_ds = dataset\ns_ds = s_ds.cache()\ns_ds = s_ds.map(denoise_image)\ns_ds = s_ds.prefetch(buffer_size = 10000)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}